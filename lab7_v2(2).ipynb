{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torchtext.vocab import Vectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mosestokenizer import *\n",
    "from sacremoses import MosesTokenizer\n",
    "from html import unescape\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "torch.cuda.manual_seed(42);\n",
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./lab7/TrainData/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You probably all already know this by now, but 5 additional episodes never aired can be viewed on ABC.com I've watched a lot of television over the years and this is possibly my favorite show, ever. It's a crime that this beautifully written and acted show was canceled. The actors that played Laura, Whit, Carlos, Mae, Damian, Anya and omg, Steven Caseman - are all incredible and so natural in those roles. Even the kids are great. Wonderful show. So sad that it's gone. Of course I wonder about the reasons it was canceled. There is no way I'll let myself believe that Ms. Moynahan's pregnancy had anything to do with it. It was in the perfect time slot in this market. I've watched all the episodes again on ABC.com - I hope they all come out on DVD some day. Thanks for reading.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[4]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем следующие правила для работы с текстом:\n",
    "1. Начало каждого примера - xxbos. Конец примера - xxeos.\n",
    "2. Конец предложения внутри примера будет обозначаться - xxsep.\n",
    "2. Загравные буквы обозначаем - xxmaj. \n",
    "3. Цитаты - xxquo.\n",
    "4. Будет использоваться Moses tokenizer.\n",
    "5. html.unescape() используется для работы со специальными символами.\n",
    "6. xxunk - неизвестные слова в тестовой выборке данных.\n",
    "7. xxpad - для обозначения отступов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moses = MosesTokenizer()\n",
    "\n",
    "def process(s, join=True):\n",
    "#     tokens = MosesTokenizer(s)\n",
    "    tokens = [unescape(t) for t in moses.tokenize(s)]\n",
    "    n_tokens = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if i == 0:\n",
    "            n_tokens.append('xxbos')\n",
    "            n_tokens.append(token.lower().replace('.', ''))\n",
    "        else:\n",
    "            if token == '.':\n",
    "                n_tokens.append('xxsep')\n",
    "            elif token[0] == '\\'' or token[0] == '\"':\n",
    "                n_tokens.append('xxquo')\n",
    "            elif token[0].isupper():\n",
    "                n_tokens.append('xxmaj')\n",
    "                n_tokens.append(token.lower().replace('.', ''))\n",
    "            else:\n",
    "                n_tokens.append(token.lower().replace('.', ''))\n",
    "    n_tokens.append('xxeos')\n",
    "    \n",
    "    if join:\n",
    "        return \" \".join(n_tokens)\n",
    "    return n_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 25000/25000 [01:15<00:00, 331.62it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Process all the text\n",
    "li = []\n",
    "for text in tqdm(list(df['text'])):\n",
    "    li.append(process(text))\n",
    "y = list(df['sentiment'])\n",
    "    \n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(li, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы конверитровать слова в индексы будем использовать словарь word2idx. И словарь idx2word - для обратной конвертации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 18750/18750 [00:00<00:00, 21365.02it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = ['xxunk', 'xxpad', 'xxbos', 'xxeos', 'xxmaj', 'xxsep', 'xxquo']\n",
    "word2idx = {vocab[i]:i for i in range(7)}\n",
    "vocab = set(vocab)\n",
    "i = 7\n",
    "\n",
    "# Build the vocabulary lookups\n",
    "for line in tqdm(X_train):\n",
    "    tokens = line.split()\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab.add(token)\n",
    "            word2idx[token] = i\n",
    "            i += 1\n",
    "            \n",
    "# Reverse the lookup table\n",
    "idx2word = {i:  word for i, word in enumerate(word2idx.keys())}\n",
    "\n",
    "# Get the vocabulary size and indicate the classes\n",
    "vocab_sz = len(vocab)\n",
    "classes = ['positive', 'negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем серилализицию для конвертации текста в индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 18750/18750 [00:01<00:00, 13291.49it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 6250/6250 [00:00<00:00, 12738.46it/s]\n"
     ]
    }
   ],
   "source": [
    "def serialize(sentence):\n",
    "    return torch.LongTensor([word2idx[token] if token in vocab else word2idx['xxunk'] for token in sentence.split()])\n",
    "\n",
    "# Serialize all data\n",
    "X_train = [serialize(s) for s in tqdm(X_train)]\n",
    "X_test = [serialize(s) for s in tqdm(X_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X_train и X_test представляют собой список тензеров, каждый содержащий последовательность индексов. Каждый индекс соответствует слову в словаре данных. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  7,  4,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22,\n",
       "        18, 23,  5,  4, 24,  4, 25,  9, 11, 26, 27, 14, 28, 29, 30, 11, 31, 32,\n",
       "        33, 34, 35, 36, 37,  5,  4, 38, 14,  4, 39,  6, 11, 40, 41, 14, 33, 42,\n",
       "         4, 39,  6, 43,  5,  4, 16, 14, 44, 45, 46, 47, 14, 48, 49, 14, 50, 15,\n",
       "        51, 52, 53,  5,  4, 54,  6, 55, 56, 54,  5,  3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем разделение на мини-батчи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(x, y, padding_value, bs=32, random_state=-1):\n",
    "    size = len(x)\n",
    "    batch_size = bs\n",
    "    if random_state > -1:\n",
    "        np.random.seed(random_state)\n",
    "    perm = np.random.permutation(size) # Shuffles list of indices\n",
    "    \n",
    "    iterator = []\n",
    "    \n",
    "    for i in range(0, size, batch_size):\n",
    "        batch_idx = perm[i:i+batch_size] # Batches a number of indices equal to bs\n",
    "        x_ = [x[i] for i in batch_idx]\n",
    "        y_ = [y[i] for i in batch_idx]\n",
    "        \n",
    "        # Sort x based on length in descending order\n",
    "        x_, y_ = zip(*sorted(zip(x_, y_), key=lambda b: len(b[0]), reverse=True))\n",
    "        \n",
    "        # Convert to tensors, and padd the sequences\n",
    "        l_ = torch.IntTensor([len(b) for b in x_])\n",
    "        x_ = rnn_utils.pad_sequence(x_, batch_first=True, padding_value=padding_value).t()\n",
    "        y_ = torch.LongTensor(y_)\n",
    "    \n",
    "        iterator.append((x_, y_, l_))\n",
    "    \n",
    "    return iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "padding_value = word2idx['xxpad']\n",
    "\n",
    "train_loader = make_batches(X_train, y_train, padding_value=padding_value, bs=batch_size, random_state=42)\n",
    "test_loader =  make_batches(X_test, y_test, padding_value=padding_value, bs=batch_size, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример батча для обучающей выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    2,     2,     2,  ...,     2,     2,     2],\n",
      "        [   11,    44, 15130,  ...,    39,    39,  3730],\n",
      "        [  584,    45,    36,  ...,   326,   672,    18],\n",
      "        ...,\n",
      "        [ 1806,     1,     1,  ...,     1,     1,     1],\n",
      "        [  386,     1,     1,  ...,     1,     1,     1],\n",
      "        [    3,     1,     1,  ...,     1,     1,     1]])\n",
      "x shape: torch.Size([949, 64])\n",
      "tensor([0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "y shape: torch.Size([64])\n",
      "tensor([949, 925, 805, 751, 676, 596, 576, 569, 557, 506, 443, 436, 435, 430,\n",
      "        385, 383, 356, 353, 336, 333, 315, 307, 294, 285, 275, 270, 267, 264,\n",
      "        258, 256, 254, 250, 244, 241, 233, 224, 222, 219, 211, 205, 204, 193,\n",
      "        193, 192, 191, 183, 183, 180, 179, 179, 173, 171, 169, 165, 157, 156,\n",
      "        156, 145, 141, 111,  92,  72,  62,  60], dtype=torch.int32)\n",
      "l shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "x, y, l = train_loader[0]\n",
    "\n",
    "print(x)\n",
    "print(\"x shape:\", x.shape)\n",
    "print(y)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(l)\n",
    "print(\"l shape:\", l.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_sz, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([949, 64, 300])\n",
      "tensor([[[ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "         [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "         [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "         ...,\n",
      "         [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "         [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "         [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225]],\n",
      "\n",
      "        [[-0.7104, -0.2730,  0.8718,  ..., -0.2636,  0.9189,  0.1502],\n",
      "         [ 1.2626, -2.6988,  1.1426,  ..., -0.6646,  0.6527, -0.9550],\n",
      "         [ 1.2716, -0.7555,  1.3774,  ...,  0.7194,  0.6065,  0.4343],\n",
      "         ...,\n",
      "         [ 0.9046,  1.0088,  0.7888,  ..., -1.8062,  0.6957, -0.5605],\n",
      "         [ 0.9046,  1.0088,  0.7888,  ..., -1.8062,  0.6957, -0.5605],\n",
      "         [-1.7563,  1.2177, -0.6656,  ...,  0.6533, -0.4488, -0.6777]],\n",
      "\n",
      "        [[-0.9203, -1.3010, -1.6578,  ...,  1.6093, -0.6787,  1.1509],\n",
      "         [-0.9141,  0.3930, -2.3449,  ...,  1.2167, -0.7928, -0.1998],\n",
      "         [ 0.8965, -0.9253, -0.0886,  ..., -0.9788, -0.7890,  1.8835],\n",
      "         ...,\n",
      "         [ 0.5206,  0.9556,  0.0049,  ..., -0.7344, -0.1458, -0.6564],\n",
      "         [-1.9365, -0.2640, -0.5347,  ...,  1.1247, -0.7690,  0.8815],\n",
      "         [ 0.3266, -0.4993, -1.4715,  ..., -1.7244,  1.6173, -0.9299]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.8455,  0.0120,  0.3902,  ...,  0.4693, -0.5957,  0.9508],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         ...,\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134]],\n",
      "\n",
      "        [[ 0.1125, -1.0147, -0.0571,  ..., -0.9760,  1.4110, -0.4437],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         ...,\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134]],\n",
      "\n",
      "        [[-2.3908,  0.3222,  1.8754,  ...,  1.7561,  0.2113,  1.4860],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         ...,\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134],\n",
      "         [-0.0318,  0.1016,  1.3433,  ...,  0.3130,  0.8050, -1.1134]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = embedding(x)\n",
    "print(\"Output shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the first item in the output: torch.Size([64, 300])\n",
      "tensor([[ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        ...,\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225]],\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the first item in the output:\", out[0].shape)\n",
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(300, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded output shape: torch.Size([949, 64, 300])\n",
      "Packed output shape: torch.Size([19601, 300])\n"
     ]
    }
   ],
   "source": [
    "(hidden, cell) = torch.zeros(1, 64, 128), torch.zeros(1, 64, 128)\n",
    "out = embedding(x)\n",
    "print(\"Embedded output shape:\", out.shape)\n",
    "\n",
    "out = rnn_utils.pack_padded_sequence(out, l)\n",
    "print(\"Packed output shape:\", out.data.shape)\n",
    "\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final timestep shape: torch.Size([64, 128])\n",
      "tensor([[ 0.0630,  0.0918,  0.0179,  ...,  0.0378,  0.0810,  0.2163],\n",
      "        [-0.0101,  0.0880,  0.0519,  ...,  0.0954,  0.0803,  0.2292],\n",
      "        [ 0.0385,  0.2314,  0.0846,  ...,  0.0659,  0.1056,  0.0205],\n",
      "        ...,\n",
      "        [ 0.0256,  0.1860,  0.0535,  ...,  0.0956,  0.1263, -0.0291],\n",
      "        [ 0.0131,  0.1697,  0.0570,  ...,  0.0898,  0.0796,  0.0112],\n",
      "        [ 0.0392,  0.0518,  0.0605,  ...,  0.0416,  0.0479,  0.3196]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = hidden[-1, :, :]\n",
    "print(\"Final timestep shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output: torch.Size([64, 2])\n",
      "tensor([[0.4619, 0.5381],\n",
      "        [0.4756, 0.5244],\n",
      "        [0.4783, 0.5217],\n",
      "        [0.4659, 0.5341],\n",
      "        [0.4530, 0.5470]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(128, 2) # Initialize with 128 units and 2 output units\n",
    "out = torch.softmax(fc(out), dim=1)\n",
    "print(\"Shape of output:\", out.shape)\n",
    "print(out[:5]) # Print the first five probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классификационная модель LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_dim, hidden_dim, output_dim):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_sz, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        return torch.zeros(1, bs, self.hidden_dim), torch.zeros(1, bs, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, X, hidden, cell, lengths):\n",
    "        out = self.embedding(X)\n",
    "        out = rnn_utils.pack_padded_sequence(out, lengths)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        out = hidden[-1, :, :]\n",
    "        out = torch.log_softmax(self.fc(out), dim=1)\n",
    "        return out, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_sz=vocab_sz, embedding_dim=300, hidden_dim=128, output_dim=2)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Make a forward pass\n",
    "(hidden, cell) = model.init_hidden(batch_size)\n",
    "out, (hidden, cell) = model(x, hidden, cell, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4844\n",
      "Loss: 0.6970\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_pred, y_acc):\n",
    "    with torch.no_grad():\n",
    "        return torch.sum(torch.max(torch.exp(y_pred), dim=1)[1] == y_acc).item() / len(y_acc)\n",
    "    \n",
    "print(\"Accuracy: {:.4f}\".format(accuracy(out, y)))\n",
    "print(\"Loss: {:.4f}\".format(criterion(out, y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_sz=vocab_sz, embedding_dim=300, hidden_dim=128, output_dim=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 293/293 [00:32<00:00,  9.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [00:02<00:00, 36.74it/s]\n",
      "  0%|                                                                                          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    1 | Train Loss 0.6848 | Train Acc 0.5422 | Test Loss 0.6762 | Test Acc 0.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 293/293 [00:31<00:00,  9.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [00:02<00:00, 36.80it/s]\n",
      "  0%|                                                                                          | 0/293 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    2 | Train Loss 0.6247 | Train Acc 0.6350 | Test Loss 0.5645 | Test Acc 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 293/293 [00:31<00:00,  9.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [00:02<00:00, 36.31it/s]\n",
      "  0%|▎                                                                                 | 1/293 [00:00<00:29,  9.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    3 | Train Loss 0.4970 | Train Acc 0.7540 | Test Loss 0.4616 | Test Acc 0.7803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 293/293 [00:31<00:00,  9.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 98/98 [00:02<00:00, 36.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    4 | Train Loss 0.4006 | Train Acc 0.8203 | Test Loss 0.4257 | Test Acc 0.8066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader, leave=True):\n",
    "        x, y, lens = batch\n",
    "        x, y, lens = x.cuda(), y.cuda(), lens.cuda()\n",
    "\n",
    "        # Initialize the hidden state\n",
    "        (hidden, cell) = model.init_hidden(x.shape[1])\n",
    "        hidden = hidden.to(device)\n",
    "        cell = cell.to(device)\n",
    "        \n",
    "        # Forward pass and backprop\n",
    "        out, (hidden, cell) = model(x, hidden, cell, lens)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "\n",
    "    # Scale accuracy and losses\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, leave=True):\n",
    "            x, y, lens = batch\n",
    "            x, y, lens = x.cuda(), y.cuda(), lens.cuda()\n",
    "\n",
    "            (hidden, cell) = model.init_hidden(x.shape[1])\n",
    "            hidden = hidden.to(device)\n",
    "            cell = cell.to(device)\n",
    "            \n",
    "            out, (hidden, cell) = model(x, hidden, cell, lens)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy(out, y)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "    \n",
    "    print(\"Epoch {:4} | Train Loss {:.4f} | Train Acc {:.4f} | Test Loss {:.4f} | Test Acc {:.4f}\".format(e, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: positive | Confidence: 0.8567\n"
     ]
    }
   ],
   "source": [
    "model.cpu()\n",
    "test = \"The movie was good! I liked the characters and the soundtrack. Overall impressive.\"\n",
    "\n",
    "# Process the sentence and unsqueeze to make a \"batch of 1\"\n",
    "test = torch.LongTensor(serialize(process(test))).unsqueeze(1) \n",
    "lengths = torch.LongTensor([len(test)])\n",
    "(hidden, cell) = model.init_hidden(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out, _ = model(test, hidden, cell, lengths)\n",
    "    out = torch.exp(out)\n",
    "    m = torch.max(out, dim=1)\n",
    "    print(\"Prediction: {} | Confidence: {:.4f}\".format(classes[m[1].item()], m[0].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Двунаправленные реккурентные сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, l = train_loader[0]\n",
    "embedding = nn.Embedding(vocab_sz, 300)\n",
    "rnn = nn.LSTM(300, 128, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded output shape: torch.Size([949, 64, 300])\n",
      "Packed output shape: torch.Size([19601, 300])\n"
     ]
    }
   ],
   "source": [
    "(hidden, cell) = torch.zeros(2, 64, 128), torch.zeros(2, 64, 128) # Note the 2 in the first dimension\n",
    "out = embedding(x)\n",
    "print(\"Embedded output shape:\", out.shape)\n",
    "\n",
    "out = rnn_utils.pack_padded_sequence(out, l)\n",
    "print(\"Packed output shape:\", out.data.shape)\n",
    "\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 64, 128])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated shape: torch.Size([64, 256])\n"
     ]
    }
   ],
   "source": [
    "h_cat = torch.cat([hidden[-1, :, :], hidden[-2, :, :]], dim=1)\n",
    "print(\"Concatenated shape:\", h_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: torch.Size([64, 2])\n",
      "tensor([[0.5321, 0.4679],\n",
      "        [0.5066, 0.4934],\n",
      "        [0.5573, 0.4427],\n",
      "        [0.5126, 0.4874],\n",
      "        [0.5096, 0.4904]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(128 * 2, 2) # Note the * 2\n",
    "out = torch.softmax(fc(h_cat), dim=1)\n",
    "print(\"Final shape:\", out.shape)\n",
    "print(out[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "\n",
    "x, y, l = train_loader[0]\n",
    "embedding = nn.Embedding(vocab_sz, 300)\n",
    "rnn = nn.LSTM(300, 128, num_layers=num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded output shape: torch.Size([949, 64, 300])\n",
      "Packed output shape: torch.Size([19601, 300])\n"
     ]
    }
   ],
   "source": [
    "(hidden, cell) = torch.zeros(num_layers, 64, 128), torch.zeros(num_layers, 64, 128) # We now generalize number of layers\n",
    "out = embedding(x)\n",
    "print(\"Embedded output shape:\", out.shape)\n",
    "\n",
    "out = rnn_utils.pack_padded_sequence(out, l)\n",
    "print(\"Packed output shape:\", out.data.shape)\n",
    "\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: torch.Size([64, 2])\n",
      "tensor([[0.4780, 0.5220],\n",
      "        [0.4784, 0.5216],\n",
      "        [0.4776, 0.5224],\n",
      "        [0.4760, 0.5240],\n",
      "        [0.4751, 0.5249]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "out = hidden[-1, :, :]\n",
    "\n",
    "fc = nn.Linear(128, 2) \n",
    "out = torch.softmax(fc(out), dim=1)\n",
    "print(\"Final shape:\", out.shape)\n",
    "print(out[:5]) # First five probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 2\n",
    "bidirectional = True\n",
    "recur_drop = 0.3\n",
    "\n",
    "x, y, l = train_loader[0]\n",
    "embedding = nn.Embedding(vocab_sz, 300)\n",
    "rnn = nn.LSTM(300, 128, num_layers=num_layers, bidirectional=bidirectional, dropout=recur_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bidirectional: # Double the first dimension if bidirectional\n",
    "    (hidden, cell) = torch.zeros(num_layers * 2, 64, 128), torch.zeros(num_layers * 2, 64, 128)\n",
    "else:\n",
    "    (hidden, cell) = torch.zeros(num_layers, 64, 128), torch.zeros(num_layers, 64, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded output shape: torch.Size([949, 64, 300])\n",
      "Packed output shape: torch.Size([19601, 300])\n"
     ]
    }
   ],
   "source": [
    "out = embedding(x)\n",
    "print(\"Embedded output shape:\", out.shape)\n",
    "\n",
    "out = rnn_utils.pack_padded_sequence(out, l)\n",
    "print(\"Packed output shape:\", out.data.shape)\n",
    "\n",
    "out, (hidden, cell) = rnn(out, (hidden, cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: torch.Size([64, 2])\n",
      "tensor([[0.4912, 0.5088],\n",
      "        [0.4786, 0.5214],\n",
      "        [0.4960, 0.5040],\n",
      "        [0.4828, 0.5172],\n",
      "        [0.4891, 0.5109]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "if bidirectional:\n",
    "    out = torch.cat([hidden[-1, :, :], hidden[-2, :, :]], dim=1)\n",
    "else:\n",
    "    out = hidden[-1, :, :]\n",
    "\n",
    "fc = nn.Linear(128 * 2, 2) if bidirectional else nn.Linear(128, 2) # Branch if bidirectional\n",
    "out = torch.softmax(fc(out), dim=1)\n",
    "print(\"Final shape:\", out.shape)\n",
    "print(out[:5]) # First five probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_dim, hidden_dim, output_dim, bidirectional, rnn_layers, recur_dropout=0.3):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_sz, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, bidirectional=bidirectional, num_layers=rnn_layers, dropout=recur_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) if bidirectional else nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        if self.rnn.bidirectional:\n",
    "            return torch.zeros(self.rnn.num_layers * 2, bs, self.hidden_dim), torch.zeros(self.rnn.num_layers * 2, bs, self.hidden_dim)\n",
    "        else:\n",
    "            return torch.zeros(self.rnn.num_layers, bs, self.hidden_dim), torch.zeros(self.rnn.num_layers, bs, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, X, hidden, cell, lengths):\n",
    "        out = self.embedding(X)\n",
    "        out = rnn_utils.pack_padded_sequence(out, lengths)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        h_cat = torch.cat([ hidden[-2, :, :], hidden[-1, :, :] ], dim=1) if self.rnn.bidirectional else hidden[-1, :, :]\n",
    "        out = torch.log_softmax(self.fc(h_cat), dim=1)\n",
    "        return out, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_sz, embedding_dim=300, hidden_dim=128, output_dim=2, \n",
    "                       bidirectional=True, rnn_layers=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▎                                                                             | 12/293 [00:03<01:29,  3.15it/s]"
     ]
    }
   ],
   "source": [
    "epochs = 4\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for batch in tqdm(train_loader, leave=True):\n",
    "        x, y, lens = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lens = lens.cuda()\n",
    "\n",
    "        (hidden, cell) = model.init_hidden(x.shape[1])\n",
    "        hidden = hidden.to(device)\n",
    "        cell = cell.to(device)\n",
    "        out, (hidden, cell) = model(x, hidden, cell, lens)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, leave=True):\n",
    "            x, y, lens = batch\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lens = lens.cuda()\n",
    "\n",
    "            (hidden, cell) = model.init_hidden(x.shape[1])\n",
    "            hidden = hidden.to(device)\n",
    "            cell = cell.to(device)\n",
    "            out, (hidden, cell) = model(x, hidden, cell, lens)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy(out, y)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "    \n",
    "    print(\"Epoch {:4} | Train Loss {:.4f} | Train Acc {:.4f} | Test Loss {:.4f} | Test Acc {:.4f}\".format(e, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "\n",
    "test = \"That movie was awful.\"\n",
    "test = torch.LongTensor(serialize(process(test))).unsqueeze(1)\n",
    "lengths = torch.LongTensor([len(test)])\n",
    "(hidden, cell) = model.init_hidden(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out, _ = model(test, hidden, cell, lengths)\n",
    "    out = torch.exp(out)\n",
    "    m = torch.max(out, dim=1)\n",
    "    print(\"Prediction: {} | Confidence: {:.4f}\".format(classes[m[1].item()], m[0].item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vectors('../input/glove840b300dtxt/glove.840B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = v['hello']\n",
    "print(\"Embedding of 'hello' dimensions:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = (v['woman'] - v['queen']).unsqueeze(0)\n",
    "\n",
    "l2_dist = nn.PairwiseDistance(p=2)\n",
    "out = l2_dist(m, w)\n",
    "\n",
    "print(\"L2 Distance:\", out.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(vocab_sz, 300)\n",
    "batch = []\n",
    "for i in range(vocab_sz):\n",
    "    batch.append(v[idx2word[i]])\n",
    "weights = torch.stack(batch)\n",
    "emb.weight.data.copy_(weights)\n",
    "emb.weight.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_sz, embedding_dim, hidden_dim, output_dim, bidirectional, rnn_layers, recur_dropout=0.3, pretrained=False, pretrained_emb=None):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        if pretrained and pretrained_emb is not None:\n",
    "            self.embedding = pretrained_emb\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(vocab_sz, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, bidirectional=bidirectional, num_layers=rnn_layers, dropout=recur_dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim) if bidirectional else nn.Linear(hidden_dim, output_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "    def init_hidden(self, bs):\n",
    "        if self.rnn.bidirectional:\n",
    "            return torch.zeros(self.rnn.num_layers * 2, bs, self.hidden_dim), torch.zeros(self.rnn.num_layers * 2, bs, self.hidden_dim)\n",
    "        else:\n",
    "            return torch.zeros(self.rnn.num_layers, bs, self.hidden_dim), torch.zeros(self.rnn.num_layers, bs, self.hidden_dim)\n",
    "        \n",
    "    def forward(self, X, hidden, cell, lengths):\n",
    "        out = self.embedding(X)\n",
    "        out = rnn_utils.pack_padded_sequence(out, lengths)\n",
    "        out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
    "        h_cat = torch.cat([ hidden[-2, :, :], hidden[-1, :, :] ], dim=1) if self.rnn.bidirectional else hidden[-1, :, :]\n",
    "        out = torch.log_softmax(self.fc(h_cat), dim=1)\n",
    "        return out, (hidden, cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMClassifier(vocab_sz, embedding_dim=300, hidden_dim=128, output_dim=2, \n",
    "                       bidirectional=True, rnn_layers=2, pretrained=True, pretrained_emb=emb).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "for e in range(1, epochs + 1):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for batch in tqdm(train_loader, leave=True):\n",
    "        x, y, lens = batch\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        lens = lens.cuda()\n",
    "\n",
    "        (hidden, cell) = model.init_hidden(x.shape[1])\n",
    "        hidden = hidden.to(device)\n",
    "        cell = cell.to(device)\n",
    "        out, (hidden, cell) = model(x, hidden, cell, lens)\n",
    "        loss = criterion(out, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += accuracy(out, y)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_acc /= len(train_loader)\n",
    "\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, leave=True):\n",
    "            x, y, lens = batch\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "            lens = lens.cuda()\n",
    "\n",
    "            (hidden, cell) = model.init_hidden(x.shape[1])\n",
    "            hidden = hidden.to(device)\n",
    "            cell = cell.to(device)\n",
    "            out, (hidden, cell) = model(x, hidden, cell, lens)\n",
    "            loss = criterion(out, y)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_acc += accuracy(out, y)\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_acc /= len(test_loader)\n",
    "    \n",
    "    print(\"Epochs {:4} | Train Loss {:.4f} | Train Acc {:.4f} | Test Loss {:.4f} | Test Acc {:.4f}\".format(e, train_loss, train_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "\n",
    "test = \"I loved the movie! The cinematography was terrific and the actors were great.\"\n",
    "test = torch.LongTensor(serialize(process(test))).unsqueeze(1)\n",
    "lengths = torch.LongTensor([len(test)])\n",
    "(hidden, cell) = model.init_hidden(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    out, _ = model(test, hidden, cell, lengths)\n",
    "    out = torch.exp(out)\n",
    "    m = torch.max(out, dim=1)\n",
    "    print(\"Prediction: {} | Confidence: {:.4f}\".format(classes[m[1].item()], m[0].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
